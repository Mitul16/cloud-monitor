"""
Main driver code that runs the agent.
This file is autorun on `python attestation_agent` command.
"""

import json
import time
from collections import deque
from concurrent.futures import ThreadPoolExecutor

import requests
import socketio

from attestation_agent.config import AUDIT_LOG, AUTH_LOG, BASE_URL, MACHINE_ID_PATH
from attestation_agent.logs import Event
from attestation_agent.logs.loggers import UsageLogger
from attestation_agent.logs.parsers import AuditParser, AuthParser
from attestation_agent.utils import load_session, save_session

# Machine ID stored in `/etc/machine-id` or in a custom location
MACHINE_ID: str = None

# Global objects below
# SocketIO object for real-time communication with the attestation server
# For instance, to receive updates from the server
sio = socketio.Client()

# ThreadPoolExecutor instance to execute loggers and parsers
# in separate threads for concurrency via multi-threading
tpe: ThreadPoolExecutor = None

# Loggers to continuously send logs to the attestation server
LOGGERS = (
    UsageLogger(),
)

# Log parsers to parse logs and send events to the attestation server
PARSERS = (
    AuthParser(AUTH_LOG),
    AuditParser(AUDIT_LOG),
)


def read_machine_id(filepath: str):
    """
    Read the machine ID from given path and set the global variable
    """
    global MACHINE_ID

    DEFAULT_PATH = "/etc/machine-id"
    path = DEFAULT_PATH if filepath is None else filepath

    with open(path) as fp:
        MACHINE_ID = fp.read().strip()
        print(f"Found machine-id: {MACHINE_ID}")


def handle_events(events: deque[Event]) -> None:
    """
    Iterate over the events, convert their data to the appropriate format
    and send to the attestation server.
    """
    while events:
        event = events.popleft()

        # Prepare data to send
        event_dict = {
            "machine_id": MACHINE_ID,
            "timestamp": event.timestamp,
            "type": event.type,
            "log_filepath": event.log_file,
            "props": "",
        }

        # Extract attributes of event
        event_props = {
            key: value for key, value in event.__dict__.items() if key not in event_dict
        }

        # Marshal the attributes and send to the attestation server
        event_dict["props"] = json.dumps(event_props)
        _ = requests.post(url=f"{BASE_URL}/api/event/add", json=event_dict)

        # TODO: Send logs separately via a logger
        # If we get a ParseError, we don't get an Event object
        # and nothing is sent to the server

        # Send raw event log (line in log file) to the attestation server
        event_log = event_dict.copy()
        _ = event_log.pop("props")
        event_log["content"] = event.raw_content
        _ = requests.post(url=f"{BASE_URL}/api/log/add", json=event_log)


def main():
    """
    Initialize the agent to run loggers and parsers in their separate threads
    """
    global sio, tpe

    # Read the machine ID from given path
    read_machine_id(MACHINE_ID_PATH)

    # Connect to attestation server, creating a websocket connection
    # for real-time communication
    print(f"Connecting to the attestation server: {BASE_URL} ... ", end="", flush=True)

    # Try to connect to the socket.io server
    try:
        sio.connect(BASE_URL)
        print(f"connected!")
        print(f"Got socketID: {sio.sid}")
    except:
        sio = None
        print(
            "Failed to connect to the attestation server."
            "Make sure the server is running and accessible."
        )

    # Load the agent session
    data = load_session()

    # Check if we had any last saved session
    if data is not None:
        # Update each parser's state so they continue from last parsed line in the logs
        for parser in PARSERS:
            filepath = parser.filepath

            if filepath in data:
                parser.set_state(data[filepath])

    # Initialize a thread pool of 8 threads
    tpe = ThreadPoolExecutor(max_workers=8)

    # Functions to run the logger and parser
    logger_runner = lambda logger: logger.run(sio)
    parser_runner = lambda parser: parser.run()

    # Run loggers and parsers in a separate thread each
    _ = tpe.map(logger_runner, LOGGERS)
    _ = tpe.map(parser_runner, PARSERS)

    # Infinite loop:
    # - pick a parser
    # - pause it, read its events, resume it
    # - pick next and repeat
    while True:
        # TODO: Use signals between threads to notify a thread pool
        # to send data to the attestation server
        # and instead just sleep in `main()` but this works...so don't change :p

        # Temporarily suspend each parser and get the events generated by it (if any)
        # and send them to the attestation server
        for parser in PARSERS:
            with parser.lock:
                events = parser.flush()

            # Handle the generated events
            handle_events(events)

        # Wait a little, so that a single core isn't overwhelmed
        time.sleep(1)


if __name__ == "__main__":
    # Run the main function in try-except
    # and exit gracefully on any error
    try:
        main()
    except (KeyboardInterrupt, SystemExit):
        # Stop and wait for the loggers and parsers to exit and release the thread pool
        print("Waiting for running threads to finish ... ", end="", flush=True)

        for logger in LOGGERS:
            logger.stop()

        for parser in PARSERS:
            parser.stop()

        # Release the thread pool
        tpe.shutdown()
        print("done!")

        # Save state of the agent, state of:
        # - loggers
        # - parsers
        data = {}

        # Read state of each parser
        for parser in PARSERS:
            data[parser.filepath] = parser.get_state()

        # Save the current session
        save_session(data)
        exit("exiting...")
